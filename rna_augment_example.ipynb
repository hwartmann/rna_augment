{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rna_augment_example.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1JFXl-Dk0_dm8tIcrOexz7611m_ZCbKFb",
      "authorship_tag": "ABX9TyO97XzCHohLLsSF37dussNr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwartmann/rna_augment/blob/master/rna_augment_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkrd6bNlcsoE",
        "colab_type": "text"
      },
      "source": [
        "# BIRA: Bias Invariant RNA-Seq Annotation Using Domain Adaptation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UDo8V2scsf_",
        "colab_type": "text"
      },
      "source": [
        "Welcome to this notebook where we'll run an example using our novel RNA-Seq annotation method.\n",
        "\n",
        "In this notebook you will be able to reproduce some of our results yourself!\n",
        "\n",
        "We'll go through the following steps:\n",
        "\n",
        "<ol>\n",
        "<li>Install the source code for BIRA as published on our github repo</li>\n",
        "<li>Load training, test and bias injection data sets</li>\n",
        "<li>Run and evaluate a full training cycle for BIRA</li>\n",
        "</ol>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfVfhczxX4zi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3073c885-5a43-4129-9814-ef1a6cd431d8"
      },
      "source": [
        "!git clone https://github.com/imsb-uke/rna_augment.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'rna_augment'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 57 (delta 10), reused 19 (delta 4), pack-reused 28\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAKeG0DgbZbN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "7212bd44-814d-443c-bf34-8608309cc8b4"
      },
      "source": [
        "!pip install rna_augment/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./rna_augment\n",
            "Building wheels for collected packages: rna-augment\n",
            "  Building wheel for rna-augment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rna-augment: filename=rna_augment-1.0-cp36-none-any.whl size=4233 sha256=fe0e1d5bbebe42b36c66b79e2b89e2b61ade9b60db4bea98dae38d46a24b3254\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2q4u1jwv/wheels/5d/a2/2a/09db3901a39f38b5a2cc80f741037a4934972c328799e0394e\n",
            "Successfully built rna-augment\n",
            "Installing collected packages: rna-augment\n",
            "Successfully installed rna-augment-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq9PDB3bZbFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rna_augment.src import bira, load_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbHP3XLSc3qA",
        "colab_type": "text"
      },
      "source": [
        "For \"source\" we load all the GTEx data originally used in the paper as well as all the SRA data as \"bias\". For \"target\" we'll load a random subset (frac=0.5) of the origianl TCGA test data. Using a subset of the TCGA data saved some space but will lead to comparable results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bucNfSM4nbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source, target, bias = load_data.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBTuWhaGc9V2",
        "colab_type": "text"
      },
      "source": [
        "BIRA comes with a number of hyperparameters that can be chosen freedly, here we provide the parameters chosen in the paper for this experiment.\n",
        "\n",
        "<ul>\n",
        "    <li>source_layers: a list of integers representing the number of nodes to be used per layer for the source and bias mapper, [512] will create one layer with 512 nodes</li>\n",
        "    <li>classifier_layers: a list of integers representing the number of nodes to be used per layer for the classifier layer, [] will only create a single output layer with n=classes</li>\n",
        "    <li>lr: learning rate applied in the second training cycle\n",
        "    <li>classes: number of classes in the data</li>\n",
        "    <li>batch_size: batch size</li>\n",
        "    <li>margin: size of margin applied in triplet loss\n",
        "    <li>print: True / False, if test accuracy should be printed after every epoch during the second training cycle    \n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYdkRk62vsUl",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "config = {'source_layers': [512],\n",
        "      'classifier_layers': [],\n",
        "      'lr': 0.0005,\n",
        "      'classes': 16,\n",
        "      'batch_size': 64,\n",
        "      'margin': 11,\n",
        "         'print': True}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwALCAnxdBk0",
        "colab_type": "text"
      },
      "source": [
        "Finally we start with the first training cyle, here we train the source mapper and the classification layer as a vanilla MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4U_JsN3vsnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = bira.Bira(source, target, bias, config=config)\n",
        "model.train_source_mapper(epochs=10)\n",
        "model.eval_source_mapper()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl0rfUTXdEiJ",
        "colab_type": "text"
      },
      "source": [
        "The accuracy above is what we achieved using GTEx to train a MLP to predict TCGA, let's see if we can do better by injecting some SRA data set biases:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV-0m6qGy3r5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train_da(epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}